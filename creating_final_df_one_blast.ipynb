{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebok that drafts a small script to pull in all the data for the WGS pathogen detection and microbiome data. It needs to pull in the following:\n",
    "    * sequence summary file from albacore\n",
    "    * two blast output files (specific database and NCBI)\n",
    "    * get the length of all porchoped reads\n",
    "    * get processing (T/F) for porchoped and nanolyze\n",
    "    * get this all into one data frame\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess as sub\n",
    "from Bio import SeqIO\n",
    "import argparse\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='''\n",
    "#This is a notebok that drafts a small script to pull in all the data for the WGS pathogen detection and microbiome data. It needs to pull in the following:\n",
    "#\n",
    "#    * sequence summary file from albacore\n",
    "#    * two blast output files (specific database and NCBI)\n",
    "#    * get the length of all porchoped reads\n",
    "#    * get processing (T/F) for porchoped and nanolyze\n",
    "#    * get this all into one data frame\n",
    "#''')\n",
    "#\n",
    "#parser.add_argument(\"BASEDIR\", help=\"base folder, supposed to have all the sub folders processed by WGS script. The same as Indir in YH_script2. DO NOT add the back slash'/' at the end!\")\n",
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets define the base folder\n",
    "BASEDIR = '/home/yiheng/test'\n",
    "#BASEDIR = args.BASEDIR\n",
    "#this will become the only flag of argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a quick check that looks for all the right folders\n",
    "folder_list = 'basecalled_data  scripts  tracking  workspace'.split(' ')\n",
    "for x in range(0,folder_list.count('')):\n",
    "    folder_list.remove('')\n",
    "#fix this test\n",
    "if not set(os.listdir(os.path.abspath(BASEDIR))) >= set (folder_list):\n",
    "    print(\"Something wrong with basefolder. check it please.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the columns that you want to pick up from sequencing summary file.\n",
    "# Here is the columns I chose for plotting out data, enough information for me so I did not pick others.\n",
    "seq_df_headers = ['read_id','passes_filtering', 'sequence_length_template', 'mean_qscore_template',\\\n",
    "                  'barcode_arrangement', 'barcode_score', 'kit', 'variant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now getting the headers from /home/yiheng/test/basecalled_data/20180524_FAH58271_albacore231/sequencing_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiheng/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,16,17,18,20,22,23,24,25,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#now get the headers sequencing_summary file\n",
    "base_called_folder = os.path.join(BASEDIR, 'basecalled_data')\n",
    "\n",
    "# here added a function to check the tar.gz file and its corresponding unzipped folder in the basecalled_data folder.  \n",
    "# If it is not unzipped, unzip it.\n",
    "for thing in os.listdir(base_called_folder):\n",
    "    judge_list = [os.path.isdir(os.path.join(base_called_folder, thing))]\n",
    "\n",
    "if any(x == True for x in judge_list):\n",
    "    seq_sum_file = os.path.join(base_called_folder, thing, 'sequencing_summary.txt')\n",
    "    if not os.path.exists(seq_sum_file):\n",
    "        print('No sequencing summary file from basecalled folder. Please go check')\n",
    "        \n",
    "    print(\"now getting the headers from %s\" % seq_sum_file)\n",
    "    seq_df = pd.read_csv(seq_sum_file, sep='\\t')\n",
    "    #capture the thing as the prefix of the fastq/fasta files in the barcode folders\n",
    "    prefix = thing\n",
    "    #might be a better way to only read in the wanted columns. Not subsetting afterwards.\n",
    "    #please go check\n",
    "    seq_df = seq_df.loc[:, seq_df_headers].copy()\n",
    "    \n",
    "elif all(x == False for x in judge_list):\n",
    "        \n",
    "    zipped_basecalled_file = os.path.join(base_called_folder, thing)\n",
    "    if zipped_basecalled_file.endswith('tar.gz'):\n",
    "        print(\"now unzipping file %s.\" % zipped_basecalled_file)\n",
    "        tar = tarfile.open(zipped_basecalled_file)\n",
    "        tar.extractall(base_called_folder.split(\".\")[0])\n",
    "        tar.close()\n",
    "    else:\n",
    "        print(\"there is something strange in the basecalled folder, please check.\")\n",
    "else:\n",
    "        print(\"there is something strange in the basecalled folder, please check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get all the rgblast_output databases done \n",
    "#rg_blast_df_file_list = []\n",
    "nt_blast_df_file_list = []\n",
    "workspace = os.path.join(BASEDIR, 'workspace')\n",
    "folder_counter = 0\n",
    "for folder in os.listdir(workspace):\n",
    "    folder = os.path.join(workspace,folder)\n",
    "    if not os.path.isdir(folder):\n",
    "        next\n",
    "    folder_counter += 1\n",
    "    for file in os.listdir(folder):\n",
    "        if not file.endswith('.rgblast_output') or not file.endswith('.ntblast_output'):\n",
    "            next\n",
    "#        if file.endswith('.rgblast_output'):\n",
    "#            rg_blast_df_file_list.append(os.path.join(folder, file))\n",
    "        if file.endswith('.ntblast_output'):\n",
    "            nt_blast_df_file_list.append(os.path.join(folder, file))\n",
    "#    if not len(nt_blast_df_file_list) == len(rg_blast_df_file_list) == folder_counter:\n",
    "#        print('Not all barcode folders have all blast output files')\n",
    "    else:\n",
    "        next\n",
    "    #print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6270eb36f22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mporechop_survived_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfolder_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfolder_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#do same for porechop + length\n",
    "#this is pretty slow. May consider parallzing.\n",
    "pc_length_dict = {}\n",
    "porechop_survived_list = []\n",
    "folder_counter = 0\n",
    "for folder in os.listdir(workspace):\n",
    "    folder_long = os.path.join(workspace,folder)\n",
    "    if not os.path.isdir(folder_long):\n",
    "        next\n",
    "    folder_counter += 1\n",
    "    porechoped_file = os.path.join(folder_long,'%s.chopped.%s.fastq'%(prefix, folder))\n",
    "    print(\"now processing porechopped file %s.\" % porechoped_file)\n",
    "    if not os.path.exists(porechoped_file):\n",
    "            print(\"Porechopped fastq missing for %s.\" % folder)\n",
    "    else:\n",
    "        for seq in SeqIO.parse(porechoped_file, 'fastq'):\n",
    "            pc_length_dict[seq.id] = len(seq.seq)\n",
    "            porechop_survived_list.append(seq.id)\n",
    "    \n",
    "#take for loop from above to loop over chopped files\n",
    "#filename = '/home/yiheng/data/Wagga_run1/workspace/barcode01/Wagga_run1_albacore202.chopped.barcode01.fastq'\n",
    "#for seq in SeqIO.parse(filename, 'fastq'):\n",
    "#    pc_length_dict[seq.id] = len(seq.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some of the porechopped reads will be splited into two reads they will have an _ in their read id\n",
    "porechop_survived_single_list = [x.split('_')[0] for x in porechop_survived_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add porechop survived column\n",
    "seq_df['pc_survived'] = seq_df['read_id'].isin(porechop_survived_single_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blast_header = ['qseqid',\n",
    " 'sseqid',\n",
    " 'evalue',\n",
    " 'bitscore',\n",
    " 'length',\n",
    " 'pident',\n",
    " 'nident',\n",
    " 'sgi',\n",
    " 'sacc',\n",
    " 'staxids',\n",
    " 'scomnames',\n",
    "'sskingdoms']\n",
    "# original headers: qseqid sseqid evalue bitscore length pident nident sgi sacc staxids sscinames scomnames sskingdoms\n",
    "def make_all_blast_df(_list, header, chopped_len_dict):\n",
    "    df = pd.DataFrame()\n",
    "    #write a check that both _list and header is a list\n",
    "    for x in _list:\n",
    "        tmp_df = pd.read_csv(x, sep='\\t',header=None, names=header)\n",
    "        first_column = tmp_df.columns[0]\n",
    "        tmp_df['read_id'] = tmp_df[first_column].apply(lambda x: str(x).split('_')[0])\n",
    "        tmp_df['read_length_pc'] = tmp_df[first_column].apply(lambda x: chopped_len_dict[x])\n",
    "        df = pd.concat([df, tmp_df.iloc[:,[0,1,2,4,5,6,8,9,10,12,13]]])\n",
    "        \n",
    "    #now reduce the columns to what we want\n",
    "    \n",
    "    #print(first_column)\n",
    "    #df['read_id'] = df.iloc[:,0].str.split('_')[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_df = make_all_blast_df(nt_blast_df_file_list, [x +'_nt' for x in  blast_header], pc_length_dict)\n",
    "print(\"now adding the nt output columns.\")\n",
    "#rg_df = make_all_blast_df(rg_blast_df_file_list, [x +'_rg' for x in  blast_header], pc_length_dict)\n",
    "#print(\"now adding the rg output columns.\")\n",
    "#reduce column number of blast dataframe to what you want before you merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to take care of porchop split reads checkin if second last character of string is _\n",
    "#make a new column of the blast_df that has the initial read_id\n",
    "#need to check how merge behaves when getting a doublcate of value in one df.\n",
    "#tmp_df = pd.merge(seq_df, rg_df,how='outer',left_on= 'read_id', right_on='read_id')\n",
    "final_df = pd.merge(seq_df, nt_df,how='outer',left_on= 'read_id', right_on='read_id')\n",
    "print(\"now creating the final dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_foler = os.path.join(BASEDIR, 'analysis')\n",
    "if not os.path.exists(analysis_foler):\n",
    "    os.mkdir(analysis_foler)\n",
    "final_df_fn = os.path.join(analysis_foler, 'summary_df_%s.tab' % (os.path.basename(BASEDIR)))\n",
    "final_df.to_csv(final_df_fn, sep='\\t', index=None)\n",
    "print(\"All done. Congratulations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
