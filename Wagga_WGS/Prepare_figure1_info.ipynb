{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is the code to plot out the figures for the WGS data\n",
    " By now you will need to run both YHscript_2 and YHscript_3 to perform the data analysis and construct the final dataframe\n",
    " All the plotting will be performed in the analysis folder under the BASEDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='This is a script to get information from figure one. It require to have a sum_df_DATE_FLOWCELLID.tab file in the analysis folder of folder of each run.')\n",
    "#parser.add_argument(\"BASEDIR\", help=\"base folder, supposed to have all the sub folders processed by WGS script. The same as Indir in YH_script2. remenber DO NOT put the backslash '/' at the end!\")\n",
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use argparse to do this\n",
    "#BASEDIR = args.BASEDIR\n",
    "BASEDIR = '/home/yiheng/data/20170617_FAH05731'\n",
    "\n",
    "# here we define the folder name of the dataframe it created by capturing the folder from the BASDIR\n",
    "folder_name = os.path.basename(BASEDIR)\n",
    "column_name = folder_name.split('_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first check if the analysis folder is there\n",
    "folder_list = 'analysis  basecalled_data  scripts  tracking  workspace'.split(' ')\n",
    "for x in range(0,folder_list.count('')):\n",
    "    folder_list.remove('')\n",
    "#fix this test\n",
    "if not set(os.listdir(os.path.abspath(BASEDIR))) == set (folder_list):\n",
    "    print(\"Something wrong with basefolder. check it please.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiheng/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# get the dataframe there\n",
    "dataframe = os.path.join(BASEDIR, 'analysis', 'summary_df_%s.tab' % folder_name)\n",
    "sum_df = pd.read_csv(dataframe, sep='\\t')\n",
    "# set the display option so easier to check through writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "################### CODE for Figure 1#############################\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########## CODE for preparing df for Figure1B\n",
    "\n",
    "#replace the nan with False for better handling\n",
    "sum_df.qseqid_rg.fillna(False, inplace=True)\n",
    "sum_df.qseqid_nt.fillna(False, inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# define different group of reads for generating graph\n",
    "ntblasthit_reads = sum_df[(sum_df.qseqid_nt != False) & (sum_df.qseqid_rg == False) & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "rgblasthit_reads = sum_df[(sum_df.qseqid_nt == False) & (sum_df.qseqid_rg != False) & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "noblasthit_reads = sum_df[(sum_df.qseqid_nt == False) & (sum_df.qseqid_rg == False) & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "rgblasthit_reads_wheat = rgblasthit_reads[rgblasthit_reads.sseqid_rg.str.contains('Wheat')]\n",
    "# creating the column for figure 1B, which is the read distribution proportion by hit on each database for each flowcellID\n",
    "total_passed_reads_df = sum_df[(sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "total_passed_reads = sum(total_passed_reads_df.sequence_length_template)\n",
    "\n",
    "nohit_prop = sum(noblasthit_reads.sequence_length_template)/total_passed_reads\n",
    "nthit_prop = sum(ntblasthit_reads.sequence_length_template)/total_passed_reads\n",
    "rghit_prop = sum(rgblasthit_reads.sequence_length_template)/total_passed_reads\n",
    "wheat_prop = sum(rgblasthit_reads_wheat.sequence_length_template)/total_passed_reads\n",
    "# here we define the column name based on the flowcell ID captured from folder_name\n",
    "column_name = folder_name.split('_')[-1]\n",
    "blasthit_df = pd.DataFrame([wheat_prop, rghit_prop, nthit_prop, nohit_prop, total_passed_reads])\n",
    "blasthit_df.columns = [column_name]\n",
    "blasthit_df.to_csv(r'/home/yiheng/analysis/WGS/%s_hit.tab' % column_name, header=column_name, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAH05731</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.141667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.263040e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.124081e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.237856e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.657718e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FAH05731\n",
       "0  9.141667e-01\n",
       "1  9.263040e-01\n",
       "2  1.124081e-02\n",
       "3  6.237856e-02\n",
       "4  5.657718e+08"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blasthit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################### CODE for preparing df for Figure1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if column_name == 'run1':\n",
    "    barcode01_reads = sum_df[(sum_df.barcode_arrangement == 'barcode02') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode02_reads = sum_df[(sum_df.barcode_arrangement == 'barcode06') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode03_reads = sum_df[(sum_df.barcode_arrangement == 'barcode04') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode04_reads = sum_df[(sum_df.barcode_arrangement == 'barcode05') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode05_reads = sum_df[(sum_df.barcode_arrangement == 'barcode03') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "\n",
    "if column_name == 'run2':\n",
    "    barcode01_reads = sum_df[(sum_df.barcode_arrangement == 'barcode07') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode02_reads = sum_df[(sum_df.barcode_arrangement == 'barcode08') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode03_reads = sum_df[(sum_df.barcode_arrangement == 'barcode09') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode04_reads = sum_df[(sum_df.barcode_arrangement == 'barcode10') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode05_reads = sum_df[(sum_df.barcode_arrangement == 'barcode11') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "\n",
    "if column_name == 'FAH05731':\n",
    "    barcode01_reads = sum_df[(sum_df.barcode_arrangement == 'barcode01') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode02_reads = sum_df[(sum_df.barcode_arrangement == 'barcode02') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode03_reads = sum_df[(sum_df.barcode_arrangement == 'barcode03') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode04_reads = sum_df[(sum_df.barcode_arrangement == 'barcode04') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode05_reads = sum_df[(sum_df.barcode_arrangement == 'barcode05') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "\n",
    "if column_name == 'FAH05432':\n",
    "    barcode01_reads = sum_df[(sum_df.barcode_arrangement == 'barcode01') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode02_reads = sum_df[(sum_df.barcode_arrangement == 'barcode02') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode03_reads = sum_df[(sum_df.barcode_arrangement == 'barcode03') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode04_reads = sum_df[(sum_df.barcode_arrangement == 'barcode04') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "    barcode05_reads = sum_df[(sum_df.barcode_arrangement == 'barcode05') & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "\n",
    "\n",
    "unclassified_reads = sum_df[(sum_df.barcode_arrangement == 'unclassified') & (sum_df.passes_filtering == True)]\n",
    "\n",
    "total_barcoded_reads = sum(barcode01_reads.sequence_length_template) + sum(barcode02_reads.sequence_length_template)\\\n",
    "                        + sum(barcode03_reads.sequence_length_template) + sum(barcode04_reads.sequence_length_template)\\\n",
    "                        + sum(barcode05_reads.sequence_length_template) + sum(unclassified_reads.sequence_length_template)\n",
    "barcode01_prop = sum(barcode01_reads.sequence_length_template)/total_barcoded_reads\n",
    "barcode02_prop = sum(barcode02_reads.sequence_length_template)/total_barcoded_reads\n",
    "barcode03_prop = sum(barcode03_reads.sequence_length_template)/total_barcoded_reads\n",
    "barcode04_prop = sum(barcode04_reads.sequence_length_template)/total_barcoded_reads\n",
    "barcode05_prop = sum(barcode05_reads.sequence_length_template)/total_barcoded_reads\n",
    "unclassified_prop = sum(unclassified_reads.sequence_length_template)/total_barcoded_reads\n",
    "\n",
    "barcode_df = pd.DataFrame([barcode01_prop, barcode02_prop, barcode03_prop, barcode04_prop, barcode05_prop, unclassified_prop])\n",
    "barcode_df.columns = [column_name]\n",
    "barcode_df.to_csv(r'/home/yiheng/analysis/WGS/%s_barcode.tab' % column_name, header=column_name, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAH05731</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.149387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.192679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.234830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FAH05731\n",
       "0  0.149387\n",
       "1  0.108778\n",
       "2  0.083516\n",
       "3  0.230810\n",
       "4  0.192679\n",
       "5  0.234830"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barcode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
