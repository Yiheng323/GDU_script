{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebok that drafts a small script to pull in all the data for the WGS pathogen detection and microbiome data. It needs to pull in the following:\n",
    "    * sequence summary file from albacore\n",
    "    * two blast output files (specific database and NCBI)\n",
    "    * get the length of all porchoped reads\n",
    "    * get processing (T/F) for porchoped and nanolyze\n",
    "    * get this all into one data frame\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess as sub\n",
    "from Bio import SeqIO\n",
    "import argparse\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='''\n",
    "This is a notebok that drafts a small script to pull in all the data for the WGS pathogen detection and microbiome data. It needs to pull in the following:\n",
    "\n",
    "    * sequence summary file from albacore\n",
    "    * two blast output files (specific database and NCBI)\n",
    "    * get the length of all porchoped reads\n",
    "    * get processing (T/F) for porchoped and nanolyze\n",
    "    * get this all into one data frame\n",
    "''')\n",
    "\n",
    "parser.add_argument(\"BASEDIR\", help=\"base folder, supposed to have all the sub folders processed by WGS script. The same as Indir in YH_script2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets define the base folder\n",
    "#BASEDIR = '/home/yiheng/test/20170617_FAH05731'\n",
    "BASEDIR = args.BASEDIR\n",
    "#this will become the only flag of argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a quick check that looks for all the right folders\n",
    "folder_list = 'basecalled_data  scripts  tracking  workspace'.split(' ')\n",
    "for x in range(0,folder_list.count('')):\n",
    "    folder_list.remove('')\n",
    "#fix this test\n",
    "if not set(os.listdir(os.path.abspath(BASEDIR))) >= set (folder_list):\n",
    "    print(\"Something wrong with basefolder. check it please.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the columns that you want to pick up from sequencing summary file.\n",
    "# Here is the columns I chose for plotting out data, enough information for me so I did not pick others.\n",
    "seq_df_headers = ['read_id','passes_filtering', 'sequence_length_template', 'mean_qscore_template',\\\n",
    "                  'barcode_arrangement', 'barcode_score', 'kit', 'variant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now getting the headers from /home/yiheng/test/20170617_FAH05731/basecalled_data/Hu_FAH05731_albacore202/sequencing_summary.txt\n"
     ]
    }
   ],
   "source": [
    "#now get the headers sequencing_summary file\n",
    "base_called_folder = os.path.join(BASEDIR, 'basecalled_data')\n",
    "\n",
    "# here added a function to check the tar.gz file and its corresponding unzipped folder in the basecalled_data folder.  \n",
    "# If it is not unzipped, unzip it.\n",
    "for thing in os.listdir(base_called_folder):\n",
    "    judge_list = [os.path.isdir(os.path.join(base_called_folder, thing))]\n",
    "\n",
    "if any(x == True for x in judge_list):\n",
    "    seq_sum_file = os.path.join(base_called_folder, thing, 'sequencing_summary.txt')\n",
    "    if not os.path.exists(seq_sum_file):\n",
    "        print('No sequencing summary file from basecalled folder. Please go check')\n",
    "    \n",
    "    print(\"now getting the headers from %s\" % seq_sum_file)\n",
    "    seq_df = pd.read_csv(seq_sum_file, sep='\\t')\n",
    "    #capture the thing as the prefix of the fastq/fasta files in the barcode folders\n",
    "    prefix = thing\n",
    "    #might be a better way to only read in the wanted columns. Not subsetting afterwards.\n",
    "    #please go check\n",
    "    seq_df = seq_df.loc[:, seq_df_headers].copy()\n",
    "    \n",
    "elif all(x == False for x in judge_list):\n",
    "        \n",
    "    zipped_basecalled_file = os.path.join(base_called_folder, thing)\n",
    "    if zipped_basecalled_file.endswith('tar.gz'):\n",
    "        print(\"now unzipping file %s.\" % zipped_basecalled_file)\n",
    "        tar = tarfile.open(zipped_basecalled_file)\n",
    "        tar.extractall(base_called_folder.split(\".\")[0])\n",
    "        tar.close()\n",
    "    else:\n",
    "        print(\"there is something strange in the basecalled folder, please check.\")\n",
    "else:\n",
    "        print(\"there is something strange in the basecalled folder, please check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get all the rgblast_output databases done \n",
    "rg_blast_df_file_list = []\n",
    "nt_blast_df_file_list = []\n",
    "workspace = os.path.join(BASEDIR, 'workspace')\n",
    "folder_counter = 0\n",
    "for folder in os.listdir(workspace):\n",
    "    folder = os.path.join(workspace,folder)\n",
    "    if not os.path.isdir(folder):\n",
    "        next\n",
    "    folder_counter += 1\n",
    "    for file in os.listdir(folder):\n",
    "        if not file.endswith('.rgblast_output') or not file.endswith('.ntblast_output'):\n",
    "            next\n",
    "        if file.endswith('.rgblast_output'):\n",
    "            rg_blast_df_file_list.append(os.path.join(folder, file))\n",
    "        if file.endswith('.ntblast_output'):\n",
    "            nt_blast_df_file_list.append(os.path.join(folder, file))\n",
    "    if not len(nt_blast_df_file_list) == len(rg_blast_df_file_list) == folder_counter:\n",
    "        print('Not all barcode folders have all blast output files')\n",
    "    else:\n",
    "        next\n",
    "    #print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode01/Hu_FAH05731_albacore202.barcode01.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode02/Hu_FAH05731_albacore202.barcode02.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode03/Hu_FAH05731_albacore202.barcode03.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode06/Hu_FAH05731_albacore202.barcode06.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode04/Hu_FAH05731_albacore202.barcode04.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode00/Hu_FAH05731_albacore202.barcode00.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode05/Hu_FAH05731_albacore202.barcode05.fastq\n",
      "now processing nanolyzed file /home/yiheng/test/20170617_FAH05731/workspace/barcode07/Hu_FAH05731_albacore202.barcode07.fastq\n"
     ]
    }
   ],
   "source": [
    "#now get all the names of the reads that survived the lyzing\n",
    "workspace = os.path.join(BASEDIR, 'workspace')\n",
    "folder_counter = 0\n",
    "nanolyze_readid_list = []\n",
    "for folder in os.listdir(workspace):\n",
    "    folder_long = os.path.join(workspace,folder)\n",
    "    if not os.path.isdir(folder_long):\n",
    "        next\n",
    "    folder_counter += 1\n",
    "    for file in os.listdir(folder_long):\n",
    "        lyzed_fastq = (os.path.join(folder_long, '%s.%s.fastq' % (prefix, folder )))\n",
    "        if not os.path.exists(lyzed_fastq):\n",
    "            print(\"No lyzed fastq file present.\")\n",
    "        elif file == '%s.%s.fastq' % (prefix, folder ):\n",
    "            print(\"now processing nanolyzed file %s\" % lyzed_fastq)\n",
    "            lyzed_fastq_name = '%s.name.tmp' % lyzed_fastq\n",
    "            #cmd = \"grep '^@' %s | cut -c1-37 > %s\"%\\\n",
    "            # (lyzed_fastq, lyzed_fastq_name)\n",
    "            #cmd = \"grep '^@' %s | cut -d:-f1 > %s\"%\\\n",
    "             #(lyzed_fastq, lyzed_fastq_name)\n",
    "            cmd = r\"grep '^@' %s | sed -e 's/@\\([a-zA-Z0-9-]\\+\\).*/\\1/' > %s\"%\\\n",
    "            (lyzed_fastq, lyzed_fastq_name)\n",
    "            #print(cmd)\n",
    "            sub.check_output(cmd, shell=True, stderr=sub.STDOUT)\n",
    "            #sub.run(cmd.split(' '))\n",
    "            nanolyze_readid_list.append(lyzed_fastq_name)\n",
    "        else:\n",
    "            next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in the tmp file of nanolyzed ids and add them to the dataframe as column\n",
    "def get_read_ids(filename_list):\n",
    "    #write a check that both _list and header is a list\n",
    "    read_id_list = []\n",
    "    for filename in filename_list:\n",
    "        tmp_list = pd.read_csv(filename, sep='\\t', header=None).loc[:,0].tolist()\n",
    "        read_id_list= read_id_list + tmp_list\n",
    "    return read_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nl_survied_list = get_read_ids(nanolyze_readid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode01/Hu_FAH05731_albacore202.chopped.barcode01.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode02/Hu_FAH05731_albacore202.chopped.barcode02.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode03/Hu_FAH05731_albacore202.chopped.barcode03.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode06/Hu_FAH05731_albacore202.chopped.barcode06.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode04/Hu_FAH05731_albacore202.chopped.barcode04.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode00/Hu_FAH05731_albacore202.chopped.barcode00.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode05/Hu_FAH05731_albacore202.chopped.barcode05.fastq.\n",
      "now processing porechopped file /home/yiheng/test/20170617_FAH05731/workspace/barcode07/Hu_FAH05731_albacore202.chopped.barcode07.fastq.\n"
     ]
    }
   ],
   "source": [
    "#do same for porechop + length\n",
    "#this is pretty slow. May consider parallzing.\n",
    "pc_length_dict = {}\n",
    "porechop_survived_list = []\n",
    "folder_counter = 0\n",
    "for folder in os.listdir(workspace):\n",
    "    folder_long = os.path.join(workspace,folder)\n",
    "    if not os.path.isdir(folder_long):\n",
    "        next\n",
    "    folder_counter += 1\n",
    "    porechoped_file = os.path.join(folder_long,'%s.chopped.%s.fastq'%(prefix, folder))\n",
    "    print(\"now processing porechopped file %s.\" % porechoped_file)\n",
    "    if not os.path.exists(porechoped_file):\n",
    "            print(\"Porechopped fastq missing for %s.\" % folder)\n",
    "    else:\n",
    "        for seq in SeqIO.parse(porechoped_file, 'fastq'):\n",
    "            pc_length_dict[seq.id] = len(seq.seq)\n",
    "            porechop_survived_list.append(seq.id)\n",
    "    \n",
    "#take for loop from above to loop over chopped files\n",
    "#filename = '/home/yiheng/data/Wagga_run1/workspace/barcode01/Wagga_run1_albacore202.chopped.barcode01.fastq'\n",
    "#for seq in SeqIO.parse(filename, 'fastq'):\n",
    "#    pc_length_dict[seq.id] = len(seq.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some of the porechopped reads will be splited into two reads they will have an _ in their read id\n",
    "porechop_survived_single_list = [x.split('_')[0] for x in porechop_survived_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add porechop survived column\n",
    "seq_df['pc_survived'] = seq_df['read_id'].isin(porechop_survived_single_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.to_csv of                                      read_id  passes_filtering  \\\n",
       "0       62a73ee6-2c8d-43be-a446-e5207e813f81              True   \n",
       "1       72072d01-818a-4b8a-ba5d-427e15d645a2              True   \n",
       "2       ef2ca42d-1299-4fbc-b002-0db746ab387c              True   \n",
       "3       114b1d7a-7e36-4edc-91f6-3ebc4d08e5bb              True   \n",
       "4       13b76f9d-a6da-440c-a201-d9d23428c1c9              True   \n",
       "5       31e90930-0b91-471d-ba29-a5c680ddac59              True   \n",
       "6       48eaaa70-c50a-4718-979f-56d3554be7fd              True   \n",
       "7       504997af-d2c1-48bf-a882-975607522fd2              True   \n",
       "8       574d135a-a26f-4662-bcff-79cce9a62851              True   \n",
       "9       5d73ab0c-b555-4994-a141-9d336471e1c5             False   \n",
       "10      6297ce52-65e9-4aec-ad94-d4d943c98607              True   \n",
       "11      681ce360-4a9a-479c-adff-6527e9249bbb             False   \n",
       "12      b10daf19-c572-4497-8ab7-e9ba203d23f7              True   \n",
       "13      b245a8d6-1508-48e4-af06-31fcce246fb7              True   \n",
       "14      b5255670-3573-4257-8cde-6ccdc3b3bb99             False   \n",
       "15      cdc00074-db20-4d00-b4d9-09ca9bf206b5              True   \n",
       "16      d101115c-67a1-4653-9c39-5330d9d5e601              True   \n",
       "17      e6200734-365b-4e63-939a-060627e13499             False   \n",
       "18      f6865501-8cd4-4002-91ee-c2a065cf9ed8              True   \n",
       "19      0c3c54e1-4e52-43bc-92be-16b1a55cbc04              True   \n",
       "20      17980305-c5f6-4588-bbaf-5558dddb7a8d              True   \n",
       "21      2d2e1684-44a2-413f-b3a6-b56ee2aced85              True   \n",
       "22      3d80a5a2-aeb7-41cd-9639-6cbbb50ffa51              True   \n",
       "23      499dbf9a-a61c-4adb-bf09-1efba2803601              True   \n",
       "24      6213aaf0-701f-467e-abfe-8331efce35f1              True   \n",
       "25      64fbb482-9b5c-47a1-b0a9-9e399e5b94c2              True   \n",
       "26      735b210d-dfeb-4e2d-a88c-45e485504ca7             False   \n",
       "27      892ecda5-aae5-489c-bc62-d531c174daa8             False   \n",
       "28      8f0a1f01-b608-4004-8399-565330a7e254              True   \n",
       "29      abb9f6ba-4c48-4fd9-9454-527f2805d030              True   \n",
       "...                                      ...               ...   \n",
       "242479  62850e6a-8de8-4fa9-a58e-b4b772574889              True   \n",
       "242480  6b09cdc0-11d2-4488-83b1-f04805b2340f              True   \n",
       "242481  6eaf70f0-8b4f-484a-8568-57b5e40aa9dd              True   \n",
       "242482  727c16c8-ab56-4e47-aed7-0c0eae047c00              True   \n",
       "242483  765bb9c1-c694-41c7-99cc-e0c313f154bf              True   \n",
       "242484  7c1165de-870b-4147-8e43-57a4c327da13              True   \n",
       "242485  93683654-7cf0-41da-9bf4-33aa18c8f1f6              True   \n",
       "242486  a0bba543-9119-4676-a8df-5d52870b8e32              True   \n",
       "242487  b9a6515f-6912-4e58-af30-a04bd852aaea              True   \n",
       "242488  be8e9367-1dcf-488d-984b-7f66695fa9d6              True   \n",
       "242489  c632ae17-906e-4033-85aa-a954f83326bb              True   \n",
       "242490  d6c2e006-b0e0-4e2b-aa0b-2bed6fa4fc10              True   \n",
       "242491  fe3c5008-d9fb-4296-809c-8b9f774541df              True   \n",
       "242492  2d2a58ec-8008-4fc3-9938-f9b1ccd79716              True   \n",
       "242493  4e45563c-129b-45ea-b2cb-8a21d3465280              True   \n",
       "242494  51352803-765d-41c7-99c3-4d5859bf8e21              True   \n",
       "242495  56575364-153f-4fa3-ae45-6cbfb6c9c9aa              True   \n",
       "242496  6a1df21e-1f0e-4547-8a05-4369f91053ea              True   \n",
       "242497  71c47f07-955c-44ac-b2de-cb8343a9b595              True   \n",
       "242498  7705a864-1954-452f-9c60-304fa357a62a              True   \n",
       "242499  778be3bd-74a2-4c04-84c4-d5525684cd82             False   \n",
       "242500  7f142030-bc7e-4000-9697-de9d11731de8              True   \n",
       "242501  86646916-cb70-4137-8189-1ac1ef3f2b3a              True   \n",
       "242502  9c0e0cd0-1f8e-410e-b289-6c0df6197b84              True   \n",
       "242503  9defdf5e-7672-4c6d-81a9-2859c4d241fb              True   \n",
       "242504  9e330410-b0cf-4a42-a984-8be5f510d28e              True   \n",
       "242505  a3ca9ef3-6b2e-4dc5-8ccb-a21b4ec28a41              True   \n",
       "242506  baf7fc1a-da54-4cfb-a8ad-6d150080a835             False   \n",
       "242507  4219193a-cb05-4dcb-a35f-7c04a71c90a6              True   \n",
       "242508  d377ee19-0a43-4a69-9d8d-e329b8b018f6              True   \n",
       "\n",
       "        sequence_length_template  mean_qscore_template barcode_arrangement  \\\n",
       "0                           1405                 9.503           barcode07   \n",
       "1                           1530                 8.137        unclassified   \n",
       "2                           1825                 9.718        unclassified   \n",
       "3                           2424                 7.315        unclassified   \n",
       "4                           3215                12.354           barcode05   \n",
       "5                           2376                 8.787        unclassified   \n",
       "6                           3990                12.361           barcode04   \n",
       "7                           2591                11.425           barcode06   \n",
       "8                           2781                 7.707        unclassified   \n",
       "9                           1205                 6.505        unclassified   \n",
       "10                          2865                13.191           barcode01   \n",
       "11                          1012                 5.911        unclassified   \n",
       "12                          2714                11.562           barcode03   \n",
       "13                          2322                10.046           barcode02   \n",
       "14                          1951                 6.827        unclassified   \n",
       "15                          2401                 7.182        unclassified   \n",
       "16                          2664                 9.403        unclassified   \n",
       "17                          3115                 6.654        unclassified   \n",
       "18                          2089                10.981           barcode01   \n",
       "19                          2176                 9.959           barcode03   \n",
       "20                          1688                11.907           barcode04   \n",
       "21                           895                 9.232           barcode06   \n",
       "22                          2050                10.335           barcode05   \n",
       "23                          4573                10.538           barcode06   \n",
       "24                          2179                 9.289           barcode05   \n",
       "25                          2964                 9.254           barcode07   \n",
       "26                             0                 0.000        unclassified   \n",
       "27                          1696                 5.757        unclassified   \n",
       "28                          1874                 8.398        unclassified   \n",
       "29                          2133                10.023           barcode06   \n",
       "...                          ...                   ...                 ...   \n",
       "242479                      4464                13.031           barcode07   \n",
       "242480                      2920                10.781           barcode03   \n",
       "242481                      3653                12.158           barcode05   \n",
       "242482                      1946                 9.778           barcode05   \n",
       "242483                      1899                11.344           barcode02   \n",
       "242484                      3463                10.723           barcode04   \n",
       "242485                      3497                13.229           barcode06   \n",
       "242486                      1897                 8.607        unclassified   \n",
       "242487                      2780                 8.225        unclassified   \n",
       "242488                      3470                12.837           barcode02   \n",
       "242489                      3358                10.175           barcode04   \n",
       "242490                      1646                13.104           barcode04   \n",
       "242491                      1479                11.244           barcode06   \n",
       "242492                      2326                11.219           barcode03   \n",
       "242493                      3499                12.069           barcode05   \n",
       "242494                      1941                12.400           barcode03   \n",
       "242495                      1925                12.113           barcode05   \n",
       "242496                      2763                12.141           barcode06   \n",
       "242497                      2300                12.056           barcode01   \n",
       "242498                      1979                10.717           barcode05   \n",
       "242499                      1041                 6.334        unclassified   \n",
       "242500                      1981                11.862           barcode05   \n",
       "242501                      1960                11.754           barcode06   \n",
       "242502                      1181                12.505           barcode02   \n",
       "242503                      1413                13.188           barcode06   \n",
       "242504                      3439                10.962           barcode06   \n",
       "242505                      3334                12.591           barcode05   \n",
       "242506                       938                 5.252        unclassified   \n",
       "242507                       688                12.368           barcode07   \n",
       "242508                      7820                12.929        unclassified   \n",
       "\n",
       "        barcode_score  kit variant  pc_survived  \n",
       "0           68.644066   BC    var1         True  \n",
       "1           57.033333   BC    var1        False  \n",
       "2           53.366665   BC    var2        False  \n",
       "3           45.423729   BC    var2        False  \n",
       "4           82.641510  LBW    var1         True  \n",
       "5           48.711864   BC    var1        False  \n",
       "6           74.847458   BC    var2         True  \n",
       "7           72.133331   BC    var2         True  \n",
       "8           42.566666   BC    var2        False  \n",
       "9           39.266666   BC    var2         True  \n",
       "10          93.864410   BC    var1         True  \n",
       "11          31.058823  RAB    var1         True  \n",
       "12          90.366669   BC    var1         True  \n",
       "13          84.203392   BC    var1         True  \n",
       "14          34.156864  RAB    var2         True  \n",
       "15          56.533333   BC    var2        False  \n",
       "16          56.641510  LBW    var2        False  \n",
       "17          58.133335   BC    var1         True  \n",
       "18          84.203392   BC    var1         True  \n",
       "19          75.627121   BC    var2         True  \n",
       "20          88.135590   BC    var2         True  \n",
       "21          76.733330   BC    var2         True  \n",
       "22          93.898308   BC    var1         True  \n",
       "23          80.881355   BC    var1         True  \n",
       "24          80.372879   BC    var2         True  \n",
       "25          83.355934   BC    var2         True  \n",
       "26           0.000000  n/a     n/a        False  \n",
       "27          37.509434  LBW    var1         True  \n",
       "28          55.866665   BC    var1        False  \n",
       "29          63.633335   BC    var2         True  \n",
       "...               ...  ...     ...          ...  \n",
       "242479      91.762711   BC    var1         True  \n",
       "242480      69.966667   BC    var2         True  \n",
       "242481      84.610168   BC    var1         True  \n",
       "242482      73.898308   BC    var1         True  \n",
       "242483      77.233330   BC    var2         True  \n",
       "242484      65.796608   BC    var1        False  \n",
       "242485      98.766670   BC    var2        False  \n",
       "242486      49.033333   BC    var2        False  \n",
       "242487      39.450981  RLB     n/a        False  \n",
       "242488      73.966103   BC    var1        False  \n",
       "242489      78.949150   BC    var1        False  \n",
       "242490      83.457626   BC    var1         True  \n",
       "242491      75.800003   BC    var2         True  \n",
       "242492      85.491524   BC    var2         True  \n",
       "242493      99.099998   BC    var2        False  \n",
       "242494      88.711861   BC    var1         True  \n",
       "242495      73.627121   BC    var1         True  \n",
       "242496      83.661018   BC    var1         True  \n",
       "242497      84.966667   BC    var2         True  \n",
       "242498      65.599998   BC    var2         True  \n",
       "242499      33.641026   NB    var2         True  \n",
       "242500      62.200001   BC    var2         True  \n",
       "242501      75.333336   BC    var2         True  \n",
       "242502      96.677963   BC    var1         True  \n",
       "242503      96.500000   BC    var2         True  \n",
       "242504      79.322037   BC    var2         True  \n",
       "242505      75.766670   BC    var2         True  \n",
       "242506      30.271187   BC    var2         True  \n",
       "242507      81.254234   BC    var1        False  \n",
       "242508      39.547169  LBW    var1        False  \n",
       "\n",
       "[242509 rows x 9 columns]>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add the nanolyze survived column\n",
    "seq_df['nl_survived'] = seq_df['read_id'].isin(nl_survied_list)\n",
    "#make porchoped survived column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blast_header = ['qseqid',\n",
    " 'sseqid',\n",
    " 'evalue',\n",
    " 'bitscore',\n",
    " 'length',\n",
    " 'pident',\n",
    " 'nident',\n",
    " 'sgi',\n",
    " 'sacc',\n",
    " 'staxids',\n",
    " 'scomnames',\n",
    "'sskingdoms']\n",
    "# original headers: qseqid sseqid evalue bitscore length pident nident sgi sacc staxids sscinames scomnames sskingdoms\n",
    "def make_all_blast_df(_list, header, chopped_len_dict):\n",
    "    df = pd.DataFrame()\n",
    "    #write a check that both _list and header is a list\n",
    "    for x in _list:\n",
    "        tmp_df = pd.read_csv(x, sep='\\t',header=None, names=header)\n",
    "        first_column = tmp_df.columns[0]\n",
    "        tmp_df['read_id'] = tmp_df[first_column].apply(lambda x: str(x).split('_')[0])\n",
    "        tmp_df['read_length_pc'] = tmp_df[first_column].apply(lambda x: chopped_len_dict[x])\n",
    "        df = pd.concat([df, tmp_df.iloc[:,[0,1,2,4,5,6,8,9,10,12,13]]])\n",
    "        \n",
    "    #now reduce the columns to what we want\n",
    "    \n",
    "    #print(first_column)\n",
    "    #df['read_id'] = df.iloc[:,0].str.split('_')[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now adding the nt output columns.\n",
      "now adding the rg output columns.\n"
     ]
    }
   ],
   "source": [
    "nt_df = make_all_blast_df(nt_blast_df_file_list, [x +'_nt' for x in  blast_header], pc_length_dict)\n",
    "print(\"now adding the nt output columns.\")\n",
    "rg_df = make_all_blast_df(rg_blast_df_file_list, [x +'_rg' for x in  blast_header], pc_length_dict)\n",
    "print(\"now adding the rg output columns.\")\n",
    "#reduce column number of blast dataframe to what you want before you merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now creating the final dataframe!\n"
     ]
    }
   ],
   "source": [
    "#need to take care of porchop split reads checkin if second last character of string is _\n",
    "#make a new column of the blast_df that has the initial read_id\n",
    "#need to check how merge behaves when getting a doublcate of value in one df.\n",
    "tmp_df = pd.merge(seq_df, rg_df,how='outer',left_on= 'read_id', right_on='read_id')\n",
    "final_df = pd.merge(tmp_df, nt_df,how='outer',left_on= 'read_id', right_on='read_id')\n",
    "print(\"now creating the final dataframe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done. Congratulations!\n"
     ]
    }
   ],
   "source": [
    "analysis_foler = os.path.join(BASEDIR, 'analysis')\n",
    "if not os.path.exists(analysis_foler):\n",
    "    os.mkdir(analysis_foler)\n",
    "final_df_fn = os.path.join(analysis_foler, 'summary_df.tab')\n",
    "final_df.to_csv(final_df_fn, sep='\\t', index=None)\n",
    "print(\"All done. Congratulations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.iloc[:200,0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def length_column(x):\n",
    "#    if x in pc_length_dict.keys():\n",
    "#        return pc_length_dict[x]\n",
    "#    else:\n",
    "#        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#porchop length column once pc_length_dict is done\n",
    "#seq_df['pc_length'] = seq_df.read_id.apply(lambda x: length_column(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
