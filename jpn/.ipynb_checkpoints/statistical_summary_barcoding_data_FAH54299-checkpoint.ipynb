{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this script is to generate basic statistical summary for MinION that contains barcodes. It can be also adapted to generate summary for basecalled data with no barcodes. The code is adapted from Gamran Green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tarfile\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define the base folder\n",
    "BASEDIR = '/home/yiheng/data/20180108_FAH18647'\n",
    "#BASEDIR = args.BASEDIR\n",
    "#this will become the only flag of argparse\n",
    "good_barcodes = ['barcode01', 'barcode02', 'barcode03', 'barcode04', 'barcode05', 'barcode06', 'barcode07', 'barcode08', 'barcode09', 'barcode10', 'barcode11', 'barcode12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns that you want to pick up from sequencing summary file.\n",
    "# Here is the columns I chose for plotting out data, enough information for me so I did not pick others.\n",
    "seq_df_headers = ['read_id','passes_filtering', 'sequence_length_template', 'mean_qscore_template',\\\n",
    "                  'barcode_arrangement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check again if the basecalled data is there\n",
    "BASECALLFOLDER = os.path.join(os.path.abspath(BASEDIR),'basecalled_data' )\n",
    "if not os.path.exists(BASECALLFOLDER):\n",
    "    print('No basecalled data in %s. Exit!' % BASEDIR)\n",
    "    #exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_FOLDER = os.path.join(os.path.abspath(BASEDIR), 'scripts')\n",
    "WORKSPACE = os.path.join(os.path.abspath(BASEDIR), 'workspace')\n",
    "TRACKING = os.path.join(os.path.abspath(BASEDIR), 'tracking')\n",
    "ANALYSIS = os.path.join(os.path.abspath(BASEDIR), 'analysis')\n",
    "if not os.path.exists(SCRIPT_FOLDER):\n",
    "    os.mkdir(SCRIPT_FOLDER)\n",
    "if not os.path.exists(WORKSPACE):\n",
    "    os.mkdir(WORKSPACE)\n",
    "if not os.path.exists(TRACKING):\n",
    "    os.mkdir(TRACKING)\n",
    "if not os.path.exists(ANALYSIS):\n",
    "    os.mkdir(ANALYSIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  len([os.path.join(BASECALLFOLDER, x) for x in os.listdir(BASECALLFOLDER) if x.endswith('tar.gz')]) == 1:\n",
    "    tar_file = [os.path.join(BASECALLFOLDER, x) for x in os.listdir(BASECALLFOLDER) if x.endswith('tar.gz')][0]\n",
    "    runid = tar_file.split('/')[-1].split('.')[0]\n",
    "    #now untar the tar gz file\n",
    "    os.chdir(BASECALLFOLDER)\n",
    "    unzip_command = 'tar -xvf %s' % (tar_file)\n",
    "    print(unzip_command)\n",
    "    unzip_command_stderr = subprocess.check_output(unzip_command, shell=True, stderr=subprocess.STDOUT)\n",
    "else:\n",
    "    print('None or mulitiple tar files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(BASECALLFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we should have generated the folder with the basecallded data\n",
    "BASECALLED_DATA_FOLDER = os.path.join(BASECALLFOLDER, tar_file.split('.')[0])\n",
    "if not os.path.exists(BASECALLED_DATA_FOLDER):\n",
    "    print(\"Something with the unzipping of the basecalled data went wrong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the contents in the zipped folder\n",
    "content = ['workspace', 'configuration.cfg', 'sequencing_summary.txt', 'pipeline.log']\n",
    "if not set(os.listdir(BASECALLED_DATA_FOLDER)) == set(content):\n",
    "    print(\"Something with the unzipping of the basecalled data might be wrong.\")\n",
    "\n",
    "BASECALLED_DATA_WORKSPACE = os.path.join(BASECALLED_DATA_FOLDER, 'workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get the headers sequencing_summary file\n",
    "base_called_folder = os.path.join(BASEDIR, 'basecalled_data')\n",
    "\n",
    "# here added a function to check the tar.gz file and its corresponding unzipped folder in the basecalled_data folder.  \n",
    "# If it is not unzipped, unzip it.\n",
    "for thing in os.listdir(base_called_folder):\n",
    "    judge_list = [os.path.isdir(os.path.join(base_called_folder, thing))]\n",
    "\n",
    "if any(x == True for x in judge_list):\n",
    "    seq_sum_file = os.path.join(base_called_folder, thing, 'sequencing_summary.txt')\n",
    "    if not os.path.exists(seq_sum_file):\n",
    "        print('No sequencing summary file from basecalled folder. Please go check')\n",
    "        \n",
    "    print(\"now getting the headers from %s\" % seq_sum_file)\n",
    "    seq_df = pd.read_csv(seq_sum_file, sep='\\t')\n",
    "    #capture the thing as the prefix of the fastq/fasta files in the barcode folders\n",
    "    prefix = thing\n",
    "    #might be a better way to only read in the wanted columns. Not subsetting afterwards.\n",
    "    #please go check\n",
    "    seq_df = seq_df.loc[:, seq_df_headers].copy()\n",
    "    \n",
    "elif all(x == False for x in judge_list):\n",
    "        \n",
    "    zipped_basecalled_file = os.path.join(base_called_folder, thing)\n",
    "    if zipped_basecalled_file.endswith('tar.gz'):\n",
    "        print(\"now unzipping file %s.\" % zipped_basecalled_file)\n",
    "        tar = tarfile.open(zipped_basecalled_file)\n",
    "        tar.extractall(base_called_folder.split(\".\")[0])\n",
    "        tar.close()\n",
    "    else:\n",
    "        print(\"there is something strange in the basecalled folder, please check.\")\n",
    "else:\n",
    "        print(\"there is something strange in the basecalled folder, please check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try to replace misclassified or unclassified barcodes into barcode00\n",
    "passed_seq_df = seq_df[seq_df.passes_filtering == True]\n",
    "all_barcodes = set(seq_df.barcode_arrangement)\n",
    "wrong_barcodes = sorted(list(all_barcodes - set(good_barcodes)))\n",
    "\n",
    "for x in wrong_barcodes:\n",
    "    seq_df.barcode_arrangement.replace(to_replace=x, value='unclassified', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passed_seq_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passed_seq_df.set_index(['barcode_arrangement', 'sequence_length_template']).unstack('barcode_arrangement')\n",
    "\n",
    "#change datatype of the value column to be numeric\n",
    "passed_seq_df.sequence_length_template = passed_seq_df.sequence_length_template.astype(float)\n",
    "\n",
    "passed_seq_df_pivot = passed_seq_df.pivot_table(values='sequence_length_template', \n",
    "                                                index='barcode_arrangement', \n",
    "                                                aggfunc=[len, np.sum, np.max, np.mean, np.median],\n",
    "                                                #aggfunc='first',\n",
    "                                                fill_value=0,\n",
    "                                                margins=True)\n",
    "#change display options  of floats\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "passed_seq_df_pivot.index.name = None\n",
    "for clmns in ['len', 'amax', 'median']:\n",
    "    passed_seq_df_pivot[clmns] = passed_seq_df_pivot[clmns].astype(int)\n",
    "passed_seq_df_pivot['sum'] = passed_seq_df_pivot['sum']/1000000\n",
    "\n",
    "passed_seq_df_pivot_formal = passed_seq_df_pivot.copy() #titles have whitespace, make fancier\n",
    "passed_seq_df_pivot_formal.rename(columns={'len': 'Number of Reads', \n",
    "                                    'sum': 'Total Length (Mbp)',\n",
    "                                    'amax': 'Max Length (bp)',\n",
    "                                    'mean': 'Mean Length (bp)',\n",
    "                                    'median': 'Median Length (bp)'}, inplace=True)\n",
    "# Saves the table summary in the /analysis/ subdirectory\n",
    "fig = plt.figure(figsize=(9,2))\n",
    "ax = fig.add_subplot(1, 1, 1, frame_on=False)\n",
    "ax.xaxis.set_visible(False)  # hide the x axis\n",
    "ax.yaxis.set_visible(False)  # hide the y axis\n",
    "\n",
    "table(ax, passed_seq_df_pivot_formal, loc='center')\n",
    "\n",
    "plt.savefig(os.path.join(ANALYSIS, \"passed_basecalled_reads_summary.png\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTRUCT HISTOGRAMS CHARTING READ DISTRIBUTION, BASED FROM THE DATAFRAME ###\n",
    "bc_list = passed_seq_df_pivot.index\n",
    "bc_list = list(bc_list)\n",
    "bc_list.remove('All')\n",
    "# Function that generates a random colour\n",
    "def random_color(x=1):\n",
    "    r = lambda: random.randint(0,255)\n",
    "    return ('#%02X%02X%02X' % (r(),r(),r()))\n",
    "\n",
    "\n",
    "#Generates a histogram showing the total read length distribution for all basecalled reads\n",
    "plt.figure(figsize=(10,5))\n",
    "passed_seq_df[passed_seq_df.sequence_length_template < passed_seq_df.sequence_length_template.mean()*4]['sequence_length_template'].hist(bins=30)\n",
    "\n",
    "plt.title('Passed Basecalled Reads - Total Read Length Distribution', y=1.03, fontsize='x-large', fontweight='bold')\n",
    "\n",
    "plt.xlabel('Read Length', fontsize=16)\n",
    "plt.xticks(np.arange(0, passed_seq_df.sequence_length_template.mean()*4 + 1, 2000))\n",
    "plt.xlim([-1000, passed_seq_df.sequence_length_template.mean()*4 + 1000])\n",
    "\n",
    "plt.ylabel('Read Count', fontsize=16)\n",
    "\n",
    "\n",
    "for idx, clmn_name in enumerate(list(passed_seq_df_pivot_formal.columns)):\n",
    "    plt.annotate(clmn_name[0] + ' = ' + str(passed_seq_df_pivot_formal[clmn_name]['All']), \n",
    "                 xy=(1, 1), \n",
    "                 xycoords='axes fraction', \n",
    "                 fontsize=16, \n",
    "                 fontweight='normal',\n",
    "                 xytext=(-20, -30 - 30*idx), \n",
    "                 textcoords='offset points', \n",
    "                 ha='right', \n",
    "                 va='top')\n",
    "    \n",
    "plt.savefig(os.path.join(ANALYSIS, \"passed_basecalled_reads_distribution.png\"), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do something like subset_df[subset_df.Length < subset_df.Length.mean()*4]\n",
    "subset_df = passed_seq_df[passed_seq_df.sequence_length_template < passed_seq_df.sequence_length_template.mean()*4]\n",
    "\n",
    "#set colormap\n",
    "# colormap = plt.cm.tab10.colors \n",
    "\n",
    "def get_color(x):\n",
    "    x = x%10\n",
    "    return ('#%02X%02X%02X' % (int(plt.cm.tab10.colors[x][0]*255),int(plt.cm.tab10.colors[x][1]*255),int(plt.cm.tab10.colors[x][2]*255)))\n",
    "\n",
    "#Generates a histogram showing the total read length distribution for all basecalled reads per barcode\n",
    "basecalled_barcodes = list(subset_df['barcode_arrangement'].unique())\n",
    "\n",
    "if len(list(subset_df['barcode_arrangement'].unique())) % 2 == 0:\n",
    "    no_of_subplots = len(basecalled_barcodes)\n",
    "else:\n",
    "    no_of_subplots = len(basecalled_barcodes) + 1\n",
    "\n",
    "#Always 2 columns, bc-count/2 rows \n",
    "no_of_subplots_pair = [int(no_of_subplots/2), 2]\n",
    "\n",
    "#Produce pairs of indices correlating to the coordinates of the subplots\n",
    "subplot_coordinates = list(product(range(no_of_subplots_pair[0]), range(no_of_subplots_pair[1])))\n",
    "subplot_coordinates_list = [list(l) for l in subplot_coordinates]\n",
    "subplot_coordinates_list_rows = [i[0] for i in subplot_coordinates_list]\n",
    "subplot_coordinates_list_columns = [i[1] for i in subplot_coordinates_list]\n",
    "\n",
    "fig, ax = plt.subplots(no_of_subplots_pair[0], no_of_subplots_pair[1], figsize=(30,20))\n",
    "\n",
    "xmax = int(subset_df.sequence_length_template.max())\n",
    "\n",
    "max_count_list = []\n",
    "for bcs in list(subset_df['barcode_arrangement'].unique()):\n",
    "    max_count_list.append(np.histogram(subset_df.loc[subset_df['barcode_arrangement'] == bcs] ['sequence_length_template'], 60)[0].max())\n",
    "max_count_list.sort()\n",
    "max_count_list_max = max_count_list[-1]\n",
    "max_count_list_max_digits = len(str(max_count_list_max))\n",
    "exact_ylim = (int(max_count_list_max / 10**(max_count_list_max_digits-1))+1)*(10**(max_count_list_max_digits-1))\n",
    "\n",
    "def applyGroupHistograms(ax_ind1, ax_ind2, bcs):\n",
    "    ax[ax_ind1, ax_ind2].hist(subset_df.groupby('barcode_arrangement')['sequence_length_template'].get_group(bcs), \n",
    "                              bins=range(0, xmax, int(xmax/60)),\n",
    "                              color=get_color(ax_ind1 * 2 + ax_ind2),\n",
    "                              #color=random_color(), \n",
    "                              alpha=0.8)\n",
    "    ax[ax_ind1, ax_ind2].set_title(bcs)\n",
    "    ax[ax_ind1, ax_ind2].set_xlabel('Read Length')\n",
    "    ax[ax_ind1, ax_ind2].set_ylabel('Read Count');\n",
    "    ax[ax_ind1, ax_ind2].set_xlim([-1000, subset_df['sequence_length_template'].max() + 1000])\n",
    "    ax[ax_ind1, ax_ind2].set_xticks(np.arange(0, xmax + 1, 1000))\n",
    "    ax[ax_ind1, ax_ind2].set_ylim(0, exact_ylim)\n",
    "    ax[ax_ind1, ax_ind2].grid(True, which='Major')\n",
    " #this adds the text to the    \n",
    "    for idx, clmn_name in enumerate(['Number of Reads', 'Total Length (Mbp)', 'Median Length (bp)']):\n",
    "        ax[ax_ind1, ax_ind2].annotate(clmn_name + ' = ' + str(int(passed_seq_df_pivot_formal.loc[bcs, clmn_name])), \n",
    "                 xy=(1, 1), \n",
    "                 xycoords='axes fraction', \n",
    "                 fontsize=16, \n",
    "                 fontweight='normal',\n",
    "                 xytext=(-20, -30 - 30*idx), \n",
    "                 textcoords='offset points', \n",
    "                 ha='right', \n",
    "                 va='top')\n",
    "\n",
    "for ax_ind1, ax_ind2, bcs, in zip(subplot_coordinates_list_rows, subplot_coordinates_list_columns, bc_list):\n",
    "    applyGroupHistograms(ax_ind1, ax_ind2, bcs)    \n",
    "\n",
    "if len(list(subset_df['barcode_arrangement'].unique())) != 0:\n",
    "    plt.delaxes(ax[subplot_coordinates_list_rows[-1], subplot_coordinates_list_columns[-1]])\n",
    "\n",
    "plt.suptitle('Basecalled Reads - Read Length Distribution By Barcode', \n",
    "             y=1.03, \n",
    "             fontsize='x-large', \n",
    "             fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ANALYSIS, 'passed_basecalled_read_distribution_bcsort.png'), bbox_inches='tight', dpi=600)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
